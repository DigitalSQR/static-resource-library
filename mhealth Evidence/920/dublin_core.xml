<?xml version="1.0" encoding="utf-8" standalone="no"?>
<dublin_core schema="dc">
  <dcvalue element="contributor" qualifier="author" language="">Calix,&#x20;Ricardo&#x20;A</dcvalue>
  <dcvalue element="contributor" qualifier="author" language="">Javadpour,&#x20;Leili</dcvalue>
  <dcvalue element="contributor" qualifier="author" language="">Knapp,&#x20;Gerald&#x20;M</dcvalue>
  <dcvalue element="date" qualifier="accessioned">2020-02-06T16:19:50Z</dcvalue>
  <dcvalue element="date" qualifier="available">2020-02-06T16:19:50Z</dcvalue>
  <dcvalue element="date" qualifier="issued" language="">2012-08-22</dcvalue>
  <dcvalue element="identifier" qualifier="uri" language="">http:&#x2F;&#x2F;dx.doi.org&#x2F;Not&#x20;available</dcvalue>
  <dcvalue element="identifier" qualifier="uri">https:&#x2F;&#x2F;lib.digitalsquare.io&#x2F;xmlui&#x2F;handle&#x2F;123456789&#x2F;2923</dcvalue>
  <dcvalue element="description" qualifier="abstract" language="">OBJECTIVE&#x20;The&#x20;goal&#x20;of&#x20;this&#x20;work&#x20;is&#x20;to&#x20;develop&#x20;and&#x20;test&#x20;an&#x20;automated&#x20;system&#x20;methodology&#x20;that&#x20;can&#x20;detect&#x20;emotion&#x20;from&#x20;text&#x20;and&#x20;speech&#x20;features&#x20;BACKGROUND&#x20;Affective&#x20;human&#x20;computer&#x20;interaction&#x20;will&#x20;be&#x20;critical&#x20;for&#x20;the&#x20;success&#x20;of&#x20;new&#x20;systems&#x20;that&#x20;will&#x20;be&#x20;prevalent&#x20;in&#x20;the&#x20;21st&#x20;century&#x20;Such&#x20;systems&#x20;will&#x20;need&#x20;to&#x20;properly&#x20;deduce&#x20;human&#x20;emotional&#x20;state&#x20;before&#x20;they&#x20;can&#x20;determine&#x20;how&#x20;to&#x20;best&#x20;interact&#x20;with&#x20;people&#x20;METHOD&#x20;Corpora&#x20;and&#x20;machine&#x20;learning&#x20;classification&#x20;models&#x20;are&#x20;used&#x20;to&#x20;train&#x20;and&#x20;test&#x20;a&#x20;methodology&#x20;for&#x20;emotion&#x20;detection&#x20;The&#x20;methodology&#x20;uses&#x20;a&#x20;stepwise&#x20;approach&#x20;to&#x20;detect&#x20;sentiment&#x20;in&#x20;sentences&#x20;by&#x20;first&#x20;filtering&#x20;out&#x20;neutral&#x20;sentences&#x20;then&#x20;distinguishing&#x20;among&#x20;positive&#x20;negative&#x20;and&#x20;five&#x20;emotion&#x20;classes&#x20;RESULTS&#x20;Results&#x20;of&#x20;the&#x20;classification&#x20;between&#x20;emotion&#x20;and&#x20;neutral&#x20;sentences&#x20;achieved&#x20;recall&#x20;accuracies&#x20;as&#x20;high&#x20;as&#x20;77&#x20;in&#x20;the&#x20;University&#x20;of&#x20;Illinois&#x20;at&#x20;Urbana&#x20;Champaign&#x20;UIUC&#x20;corpus&#x20;and&#x20;61&#x20;in&#x20;the&#x20;Louisiana&#x20;State&#x20;University&#x20;medical&#x20;drama&#x20;LSU&#x20;MD&#x20;corpus&#x20;for&#x20;emotion&#x20;samples&#x20;Once&#x20;neutral&#x20;sentences&#x20;were&#x20;filtered&#x20;out&#x20;the&#x20;methodology&#x20;achieved&#x20;accuracy&#x20;scores&#x20;for&#x20;detecting&#x20;negative&#x20;sentences&#x20;as&#x20;high&#x20;as&#x20;92&#x20;3&#x20;CONCLUSION&#x20;Results&#x20;of&#x20;the&#x20;feature&#x20;analysis&#x20;indicate&#x20;that&#x20;speech&#x20;spectral&#x20;features&#x20;are&#x20;better&#x20;than&#x20;speech&#x20;prosodic&#x20;features&#x20;for&#x20;emotion&#x20;detection&#x20;Accumulated&#x20;sentiment&#x20;composition&#x20;text&#x20;features&#x20;appear&#x20;to&#x20;be&#x20;very&#x20;important&#x20;as&#x20;well&#x20;This&#x20;work&#x20;contributes&#x20;to&#x20;the&#x20;study&#x20;of&#x20;human&#x20;communication&#x20;by&#x20;providing&#x20;a&#x20;better&#x20;understanding&#x20;of&#x20;how&#x20;language&#x20;factors&#x20;help&#x20;to&#x20;best&#x20;convey&#x20;human&#x20;emotion&#x20;and&#x20;how&#x20;to&#x20;best&#x20;automate&#x20;this&#x20;process&#x20;APPLICATION&#x20;Results&#x20;of&#x20;this&#x20;study&#x20;can&#x20;be&#x20;used&#x20;to&#x20;develop&#x20;better&#x20;automated&#x20;assistive&#x20;systems&#x20;that&#x20;interpret&#x20;human&#x20;language&#x20;and&#x20;respond&#x20;to&#x20;emotions&#x20;through&#x20;3&#x20;D&#x20;computer&#x20;graphics</dcvalue>
  <dcvalue element="description" qualifier="provenance" language="en">Made&#x20;available&#x20;in&#x20;DSpace&#x20;on&#x20;2020-02-06T16:19:50Z&#x20;(GMT).&#x20;No.&#x20;of&#x20;bitstreams:&#x20;0&#x0A;&#x20;&#x20;Previous&#x20;issue&#x20;date:&#x20;2012-08-22</dcvalue>
  <dcvalue element="relation" qualifier="uri" language="">Human&#x20;factors</dcvalue>
  <dcvalue element="title" qualifier="none" language="en">Detection&#x20;of&#x20;affective&#x20;states&#x20;from&#x20;text&#x20;and&#x20;speech&#x20;for&#x20;real-time&#x20;human--computer&#x20;interaction.</dcvalue>
</dublin_core>
